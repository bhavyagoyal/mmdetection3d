#!/usr/bin/env bash
#SBATCH --partition=research
#SBATCH --cpus-per-task=8
#SBATCH --gres=gpu:gtx1080:1
#SBATCH --mem=16000
#SBATCH --time=96:0:0
###SBATCH --nodelist=euler03
###SBATCH --exclude=euler01,euler02,euler03
#SBATCH -o slurm.%j.%N.out # STDOUT
#SBATCH -e slurm.%j.%N.err # STDERR
#SBATCH --job-name=mmdt3d
###SBATCH --no-requeue

#conda 23.3.1, cuda11.8
#conda install pytorch==2.0.0 torchvision==0.15.0 torchaudio==2.0.0 pytorch-cuda=11.8 -c pytorch -c nvidia
#install mmcv without mim, using pip instead
#pip install "mmcv>=2.0.0rc4" -f  https://download.openmmlab.com/mmcv/dist/cu118/torch2.0.0/index.html
#pip install mmdet
#git clone https://github.com/open-mmlab/mmdetection3d.git -b dev-1.x
## "-b dev-1.x" means checkout to the `dev-1.x` branch.
#cd mmdetection3d
#pip install -v -e .


module load anaconda/mini/23.3.1
module load nvidia/cuda/11.8.0
bootstrap_conda
conda activate openmmlab

CHECKPOINT=checkpoints/votenet_16x8_sunrgbd-3d-10class_20210820_162823-bf11f014.pth
EXPERIMENT=work_dir_py/5_5_gtdepthall_worepeat/votenet_8xb16_sunrgbd-3d/
EXPERIMENT=work_dir_py/5_100_filteringpeaks_points2048+densitynormed+weighted/votenet_8xb16_sunrgbd-3d/
EXPERIMENT=work_dir_py/testing/votenet_8xb16_sunrgbd-3d/
CHECKPOINT=${EXPERIMENT}/epoch_36.pth
DATAPATH=py/points_5_5_gtdepthall
#DATAPATH=py/points_5_100_filteringpeaks
GPUS=1
PORTUSED=$(( $RANDOM + 10000 ))


# Cache files in /tmp if io is slow over network mount disk
# Not tested thoroughly
#TMPFOLDER=/tmp/bhavya/
#TMPDATA=${TMPFOLDER}${DATAPATH}
#USECACHE=false
#if [ "$USECACHE" = true ]; then
#mkdir -p $TMPFOLDER
#cp --parent -u data/sunrgbd/$DATAPATH/00{6,7,8,9}*.bin ${TMPFOLDER} &
#fi



#CUDA_VISIBLE_DEVICES=0 python -u tools/train.py configs/votenet/votenet_8xb16_sunrgbd-3d.py --auto-scale-lr --resume --cfg-options \
PORT=${PORTUSED} ./tools/dist_train.sh configs/votenet/votenet_8xb16_sunrgbd-3d.py ${GPUS} --auto-scale-lr --resume --cfg-options \
	train_dataloader.dataset.dataset.data_prefix.pts=${DATAPATH} \
	val_dataloader.dataset.data_prefix.pts=${DATAPATH} \
	train_dataloader.batch_size=8 \
	work_dir=${EXPERIMENT} \
	default_hooks.checkpoint.interval=1 \
	train_dataloader.num_workers=4 \




#	train_dataloader.dataset.pipeline.4.num_points=2048 \
#	val_dataloader.dataset.pipeline.1.transforms.2.num_points=2048 \
#	train_dataloader.dataset.pipeline.0.load_dim=7 \
#	val_dataloader.dataset.pipeline.0.load_dim=7 \
#	train_dataloader.dataset.pipeline.0.norm_probabilities=True \
#	val_dataloader.dataset.pipeline.0.norm_probabilities=True \
#	train_dataloader.dataset.pipeline.0.use_dim="[0,1,2,3]" \
#	val_dataloader.dataset.pipeline.0.use_dim="[0,1,2,3]" \
#	model.backbone.in_channels=5 \



#	val_dataloader.dataset.pipeline.1.transforms.2.probability_sampling=True \
#	train_dataloader.dataset.dataset.pipeline.4.probability_sampling=True \






#	model.backbone.fps_sample_range_list="[2049,-1,-1,-1]" \
#	model.weighted_score=True \
#	train_dataloader.dataset.dataset.pipeline.0.cache_prefix="${TMPFOLDER}" \










	#model.backbone.sa_mask=True \
#	model.backbone.sa_cfg.pool_mod='avgmax' \
#	train_dataloader.dataset.dataset.ann_file='sunrgbd_infos_train_short.pkl' \
#	val_dataloader.dataset.ann_file='sunrgbd_infos_val_short.pkl'



#if [ "$USECACHE" = true ]; then
#rm -rf ${TMPDATA}
#fi
 
